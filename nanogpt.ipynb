{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/steelannelida/nanoGPT/blob/master/nanogpt.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YtaaN1C1BT8P",
        "outputId": "d3a912d5-d6db-4021-ef9b-8174e9acba65"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'nanoGPT' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/steelannelida/nanoGPT.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vq-zNSZYCPTL",
        "outputId": "68cc2988-50d4-4b46-8202-562b411f4931"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.46.2)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (3.1.0)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.10/dist-packages (0.8.0)\n",
            "Requirement already satisfied: wandb in /usr/local/lib/python3.10/dist-packages (0.18.7)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.6)\n",
            "Requirement already satisfied: triton in /usr/local/lib/python3.10/dist-packages (3.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.9.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.26.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.11.2)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.7)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.1.43)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.10/dist-packages (from wandb) (4.3.6)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (4.25.5)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.18.0)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.10/dist-packages (from wandb) (1.3.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (75.1.0)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (0.2.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.17.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.11)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch numpy transformers datasets tiktoken wandb tqdm triton\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NSPqPSIgCAGI",
        "outputId": "2efcbedf-0e8d-4156-c039-d884769a7874"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train has 301,966 tokens\n",
            "val has 36,059 tokens\n"
          ]
        }
      ],
      "source": [
        "!yes  | python nanoGPT/data/shakespeare/prepare.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vziHkeCMFLt8"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "CDskvzaJC2dL",
        "outputId": "63e71693-a4b9-43bc-e3a4-79a7098f35be"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'sandwitch'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "with open('nanoGPT/data/shakespeare/input.txt') as f:\n",
        "  text = f.read()\n",
        "\n",
        "chars = sorted(set(text))\n",
        "vocab_size=len(chars)\n",
        "stoi = {ch: i for i, ch in enumerate(chars)}\n",
        "\n",
        "def encode(t):\n",
        "  return [stoi[c] for c in t]\n",
        "\n",
        "def decode(seq):\n",
        "  return ''.join([chars[i] for i in seq])\n",
        "\n",
        "decode(encode(\"sandwitch\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "emtQzoojEXUI"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "data = torch.tensor(encode(text), device=device)\n",
        "data.shape, data.dtype\n",
        "\n",
        "n = int(data.shape[0] * 0.9)\n",
        "train_data = data[:n]\n",
        "valid_data = data[n:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a3O_mdTCJyKW",
        "outputId": "205cdeb9-3804-4ea5-c52a-dda5f7315f07"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "t\n",
            "Come up to the truth. So have we thought it good\n",
            "From our free person she should be confined,\n",
            "Lest that the treachery of the t\n",
            "\n",
            "Come up to the truth. So have we thought it good\n",
            "From our free person she should be confined,\n",
            "Lest that the treachery of the tw\n"
          ]
        }
      ],
      "source": [
        "#torch.manual_seed(1337)\n",
        "\n",
        "\n",
        "def get_batch(data_set=train_data, batch_size=32, seq_length=128):\n",
        "    x = torch.zeros([batch_size, seq_length], dtype=torch.int, device=device)\n",
        "    y = torch.zeros([batch_size, seq_length], dtype=torch.int, device=device)\n",
        "    for b in range(batch_size):\n",
        "        t = torch.randint(0, data_set.shape[0] - seq_length - 1, [1])\n",
        "        x[b] = data_set[t:t+seq_length]\n",
        "        y[b] = data_set[t+1:t+seq_length+1]\n",
        "    return x, y\n",
        "\n",
        "x, y = get_batch()\n",
        "print(decode(x[13]))\n",
        "print(decode(y[13]))"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8qdTNUaLJpyc"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "d6Huvb7cNXcN",
        "outputId": "81d3e8b7-4295-45df-f805-76aef702523a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-7-926c060b2b42>:78: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  idx = torch.tensor(idx, device=device)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'hellomH-lwwv,?R'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class DecoderLayer(nn.Module):\n",
        "  def __init__(self, embed_size=256, wide_size=1024, nheads=16, dropout=0.5):\n",
        "    super().__init__()\n",
        "    # self.attn = nn.MultiheadAttention(embed_size, nheads,\n",
        "    #                                   batch_first=True)\n",
        "    self.nheads = nheads\n",
        "    self.head_size = embed_size // nheads\n",
        "    self.pre_attn = nn.Linear(embed_size, 3 * embed_size)\n",
        "    self.post_attn = nn.Linear(embed_size, embed_size)\n",
        "    self.ln1 = nn.LayerNorm(embed_size)\n",
        "    self.ln2 = nn.LayerNorm(embed_size)\n",
        "    self.lin1 = nn.Linear(embed_size, wide_size)\n",
        "    self.lin2 = nn.Linear(wide_size, embed_size)\n",
        "    self.drop = nn.Dropout(dropout)\n",
        "\n",
        "  def forward(self, x, mask):\n",
        "    N, L, C = x.shape\n",
        "    x = self.ln1(x)\n",
        "    #a, w = self.attn.forward(x, x, x, attn_mask=mask, is_causal=True)\n",
        "    kqv = self.pre_attn(x).view(N, L, self.nheads, 3*self.head_size).permute(0, 2, 1, 3)\n",
        "    k = kqv[:,:,:,:self.head_size]\n",
        "    q = kqv[:,:,:,self.head_size : 2*self.head_size]\n",
        "    v = kqv[:,:,:,2*self.head_size:]\n",
        "    av = nn.functional.scaled_dot_product_attention(q, k, v, mask.view(1, L, L))\n",
        "    a = self.post_attn(av.permute(0, 2, 1, 3).view(N, L, C))\n",
        "    x = x + self.drop(a)\n",
        "    x = self.ln2(x)\n",
        "    xx = self.lin1(x)\n",
        "    xx = nn.functional.gelu(xx)\n",
        "    y = self.lin2(xx)\n",
        "    return x + y\n",
        "\n",
        "class RnnLayer(nn.Module):\n",
        "  def __init__(self, embed_size=256, wide_size=1024, dropout=0.5, **kwargs):\n",
        "    super().__init__()\n",
        "    # self.attn = nn.MultiheadAttention(embed_size, nheads,\n",
        "    #                                   batch_first=True)\n",
        "    self.rnn = nn.LSTM(embed_size, embed_size)\n",
        "    self.ln1 = nn.LayerNorm(embed_size)\n",
        "    self.ln2 = nn.LayerNorm(embed_size)\n",
        "    self.lin1 = nn.Linear(embed_size, wide_size)\n",
        "    self.lin2 = nn.Linear(wide_size, embed_size)\n",
        "    self.drop = nn.Dropout(dropout)\n",
        "\n",
        "  def forward(self, x, mask):\n",
        "    N, L, C = x.shape\n",
        "    x = self.ln1(x)\n",
        "    #a, w = self.attn.forward(x, x, x, attn_mask=mask, is_causal=True)\n",
        "    a, h = self.rnn(x)\n",
        "    x = x + self.drop(a)\n",
        "    x = self.ln2(x)\n",
        "    xx = self.lin1(x)\n",
        "    xx = nn.functional.gelu(xx)\n",
        "    y = self.lin2(xx)\n",
        "    return x + y\n",
        "\n",
        "\n",
        "class LM(nn.Module):\n",
        "  def __init__(self, vocab_size, decoder=DecoderLayer, embed_size=256, nheads=16, max_pos=2048, num_layers=3, dropout=0.5):\n",
        "    super().__init__()\n",
        "    self.embeddings = nn.Embedding(vocab_size, embed_size)\n",
        "    self.pos_embeddings = nn.Embedding(max_pos, embed_size)\n",
        "    self.layers = [\n",
        "        decoder(embed_size=embed_size, wide_size=4 * embed_size,\n",
        "                     nheads=nheads, dropout=dropout)\n",
        "        for _ in range(num_layers)\n",
        "    ]\n",
        "    for i, layer in enumerate(self.layers):\n",
        "      self.add_module(f'decoder-{i}', layer)\n",
        "    self.ln = nn.LayerNorm(embed_size)\n",
        "    self.out = nn.Linear(embed_size, vocab_size)\n",
        "    self.max_pos = max_pos\n",
        "    self.to(device)\n",
        "\n",
        "  def forward(self, idx):\n",
        "    idx = torch.tensor(idx, device=device)\n",
        "    l = idx.shape[-1]\n",
        "    pe = self.pos_embeddings(torch.arange(0, l, device=device))\n",
        "    e = self.embeddings(idx)\n",
        "    e = e + pe.view(1, *pe.shape)\n",
        "    mask = torch.tril(torch.ones([l, l], dtype=torch.bool, device=device))\n",
        "    #print(mask)\n",
        "    #print(w)\n",
        "    for layer in self.layers:\n",
        "      e = layer(e, mask)\n",
        "    logits = self.out.forward(self.ln(e))\n",
        "    return logits\n",
        "\n",
        "  def generate(self, prompt, l):\n",
        "    prompt = torch.tensor(prompt)\n",
        "    pl = prompt.shape[0]\n",
        "    result = torch.zeros([pl + l], dtype=torch.int, device=device)\n",
        "    result[:pl] = prompt\n",
        "    for i in range(l):\n",
        "      logits = self.forward(result[:pl + i])\n",
        "      sm = logits[:,-1].flatten().softmax(0)\n",
        "      next_idx = torch.multinomial(sm, 1)\n",
        "      result[i+pl] = next_idx\n",
        "    return result\n",
        "\n",
        "model = LM(vocab_size)\n",
        "\n",
        "k=x\n",
        "q=x[:,:-1]\n",
        "x, y = get_batch()\n",
        "model.forward(x)\n",
        "decode(model.generate(encode('hello'), 10))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kmqqz6egO50w",
        "outputId": "15fdc8a8-ee32-4d86-cc96-a4860b66102b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-7-926c060b2b42>:78: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  idx = torch.tensor(idx, device=device)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(4.3366, device='cuda:0', grad_fn=<NllLoss2DBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "x, y = get_batch()\n",
        "logits = model(x)\n",
        "loss_fun = nn.CrossEntropyLoss()\n",
        "loss = loss_fun(logits.permute(0, 2, 1), y.long())\n",
        "loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "0nkmynipacvK"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(1337)\n",
        "\n",
        "model1 = LM(vocab_size, num_layers=8)\n",
        "model2 = LM(vocab_size, decoder=RnnLayer, num_layers=8)\n",
        "opt1 = torch.optim.AdamW(model1.parameters(), lr=1e-3)\n",
        "opt2 = torch.optim.AdamW(model2.parameters(), lr=1e-3)\n",
        "xv, yv = get_batch(valid_data, batch_size=256)\n",
        "loss_history1 = []\n",
        "loss_history2 = []"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bW5j36nJqy2o"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib import pyplot as plt\n",
        "import IPython.display as ipd\n",
        "\n",
        "plt.plot([1,2,3,6,4,5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "PwWENgNbij59",
        "outputId": "11d6ee1a-7e10-40c2-d3ee-7fbccb4302b1"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7df735032e00>]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 463
        },
        "id": "m5yC7g_TUpZz",
        "outputId": "54153ac1-c56f-4c58-8590-a9a42b38152f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-7-926c060b2b42>:78: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  idx = torch.tensor(idx, device=device)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-926c060b2b42>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0;31m#print(w)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m       \u001b[0me\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m     \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mln\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-926c060b2b42>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, mask)\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkqv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mav\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscaled_dot_product_attention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost_attn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mav\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mln2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead."
          ]
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "\n",
        "torch.set_float32_matmul_precision('medium')\n",
        "for step in range(5000):\n",
        "  x, y = get_batch(batch_size=32, seq_length=128)\n",
        "  with torch.autocast(device_type='cuda', dtype=torch.float16):\n",
        "    model1.train()\n",
        "    logits = model1.forward(x)\n",
        "    loss1 = loss_fun(logits.permute(0, 2, 1), y.long())\n",
        "\n",
        "    model2.train()\n",
        "    logits = model2.forward(x)\n",
        "    loss2 = loss_fun(logits.permute(0, 2, 1), y.long())\n",
        "\n",
        "  loss1.backward()\n",
        "  opt1.step()\n",
        "  opt1.zero_grad()\n",
        "\n",
        "  loss2.backward()\n",
        "  opt2.step()\n",
        "  opt2.zero_grad()\n",
        "\n",
        "\n",
        "  if step % 10 == 0:\n",
        "    with torch.no_grad():\n",
        "      with torch.autocast(device_type='cuda', dtype=torch.bfloat16):\n",
        "        model1.eval()\n",
        "        vlogits = model1.forward(xv)\n",
        "        vloss1 = loss_fun(vlogits.permute(0,2,1), yv.long())\n",
        "\n",
        "        model2.eval()\n",
        "        vlogits = model2.forward(xv)\n",
        "        vloss2 = loss_fun(vlogits.permute(0,2,1), yv.long())\n",
        "\n",
        "      loss_history1.append(float(vloss1))\n",
        "      loss_history2.append(float(vloss2))\n",
        "\n",
        "      plt.plot(loss_history1)\n",
        "      plt.plot(loss_history2)\n",
        "      ipd.clear_output(True)\n",
        "      plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "  model2.eval()\n",
        "  model2.forward(xv)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oWdMWqrin1vz",
        "outputId": "2ad94207-a74e-4ee8-f115-06476136ade1"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-7-926c060b2b42>:78: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  idx = torch.tensor(idx, device=device)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.profiler.profile(with_stack=True, profile_memory=True) as prof:\n",
        "  x, y = get_batch(batch_size=32, seq_length=128)\n",
        "  with torch.autocast(device_type='cuda', dtype=torch.float16):\n",
        "    model.train()\n",
        "    logits = model.forward(x)\n",
        "    loss = loss_fun(logits.permute(0, 2, 1), y.long())\n",
        "\n",
        "  loss.backward()\n",
        "  opt.step()\n",
        "  opt.zero_grad()\n",
        "\n",
        "\n",
        "print(prof.export_chrome_trace('trace3.json'))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "WrLev-eo-yVi",
        "outputId": "89364b26-09f8-4cdf-e8ac-0378e7d57605"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-7-926c060b2b42>:78: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  idx = torch.tensor(idx, device=device)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'opt' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-5fa63b21d045>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m   \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m   \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m   \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'opt' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -lh trace2.json"
      ],
      "metadata": {
        "id": "27DituDcAbN9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t3owgLEWXeJI"
      },
      "outputs": [],
      "source": [
        "with torch.no_grad():\n",
        "  with torch.autocast(device_type='cuda', dtype=torch.float16):\n",
        "    model.eval()\n",
        "    print(decode(model.generate(encode('To dream'), 256)))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZqWfDKngMlVJ"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#plt.imshow(model.embeddings.weight.detach().cpu().numpy())\n",
        "plt.plot(model.pos_embeddings.weight[:,37].detach().cpu().numpy())\n",
        "# plt.plot(model.pos_embeddings.weight[:,4].detach().cpu().numpy())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sn9Q42SwPPpT"
      },
      "outputs": [],
      "source": [
        "from sklearn.manifold import TSNE\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "tsne = TSNE()\n",
        "y = tsne.fit_transform(model.embeddings.weight.detach().T.cpu().numpy())\n",
        "\n",
        "plt.scatter(y[:,0], y[:,1], s=1, alpha=0.1)\n",
        "for i, c in enumerate(chars):\n",
        "  plt.text(y[i,0], y[i,1], c)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TfCg1bDIQblk"
      },
      "outputs": [],
      "source": [
        "model.embeddings.weight.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xlc_aDPnPmLK"
      },
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyN1kaL3RqGy4EzeFElqeEx7",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}